{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open(\"./X.pickle\", \"rb\"))\n",
    "Y = pickle.load(open(\"./Y.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X / 255.0)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "546/546 [==============================] - 69s 121ms/step - loss: 0.6494 - accuracy: 0.6123 - val_loss: 0.6008 - val_accuracy: 0.6904\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 68s 125ms/step - loss: 0.5757 - accuracy: 0.7038 - val_loss: 0.5693 - val_accuracy: 0.7083\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 67s 123ms/step - loss: 0.5223 - accuracy: 0.7432 - val_loss: 0.5020 - val_accuracy: 0.7568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e471278e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, Y, batch_size=32, epochs=3, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Cats-vs-dogs-CNN-{}\".format(int(time.time()))\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"Y.pickle\",\"rb\")\n",
    "Y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X/255.0)\n",
    "Y = np.array(Y)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "546/546 [==============================] - 433s 789ms/step - loss: 0.6569 - accuracy: 0.6105 - val_loss: 0.6326 - val_accuracy: 0.6443\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 425s 778ms/step - loss: 0.5897 - accuracy: 0.6892 - val_loss: 0.5877 - val_accuracy: 0.7030\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 419s 767ms/step - loss: 0.5478 - accuracy: 0.7215 - val_loss: 0.5288 - val_accuracy: 0.7401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e36753640>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "model.fit(X, Y,\n",
    "          batch_size=32,\n",
    "          epochs=3,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 4 Tensor board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-32-node-0-dense-1621595061\n",
      "2-conv-32-node-0-dense-1621595061\n",
      "3-conv-32-node-0-dense-1621595061\n",
      "1-conv-64-node-0-dense-1621595061\n",
      "2-conv-64-node-0-dense-1621595061\n",
      "3-conv-64-node-0-dense-1621595061\n",
      "1-conv-128-node-0-dense-1621595061\n",
      "2-conv-128-node-0-dense-1621595061\n",
      "3-conv-128-node-0-dense-1621595061\n",
      "1-conv-32-node-1-dense-1621595061\n",
      "2-conv-32-node-1-dense-1621595061\n",
      "3-conv-32-node-1-dense-1621595061\n",
      "1-conv-64-node-1-dense-1621595061\n",
      "2-conv-64-node-1-dense-1621595061\n",
      "3-conv-64-node-1-dense-1621595061\n",
      "1-conv-128-node-1-dense-1621595061\n",
      "2-conv-128-node-1-dense-1621595061\n",
      "3-conv-128-node-1-dense-1621595061\n",
      "1-conv-32-node-2-dense-1621595061\n",
      "2-conv-32-node-2-dense-1621595061\n",
      "3-conv-32-node-2-dense-1621595061\n",
      "1-conv-64-node-2-dense-1621595061\n",
      "2-conv-64-node-2-dense-1621595061\n",
      "3-conv-64-node-2-dense-1621595061\n",
      "1-conv-128-node-2-dense-1621595061\n",
      "2-conv-128-node-2-dense-1621595061\n",
      "3-conv-128-node-2-dense-1621595061\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-node-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Cats-vs-dogs-CNN-{}\".format(int(time.time()))\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"Y.pickle\",\"rb\")\n",
    "Y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "546/546 [==============================] - 15s 27ms/step - loss: 0.6322 - accuracy: 0.6424 - val_loss: 0.5848 - val_accuracy: 0.6877\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 14s 25ms/step - loss: 0.5609 - accuracy: 0.7144 - val_loss: 0.5506 - val_accuracy: 0.7284\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 14s 25ms/step - loss: 0.5240 - accuracy: 0.7439 - val_loss: 0.5385 - val_accuracy: 0.7266\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 24s 42ms/step - loss: 0.6246 - accuracy: 0.6444 - val_loss: 0.5688 - val_accuracy: 0.7092\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 27s 50ms/step - loss: 0.5463 - accuracy: 0.7249 - val_loss: 0.5384 - val_accuracy: 0.7286\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 29s 53ms/step - loss: 0.5095 - accuracy: 0.7508 - val_loss: 0.4972 - val_accuracy: 0.7579\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 29s 51ms/step - loss: 0.6549 - accuracy: 0.6077 - val_loss: 0.6191 - val_accuracy: 0.6557\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 28s 52ms/step - loss: 0.5764 - accuracy: 0.6965 - val_loss: 0.5463 - val_accuracy: 0.7242\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 29s 53ms/step - loss: 0.5250 - accuracy: 0.7368 - val_loss: 0.5057 - val_accuracy: 0.7564\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 24s 44ms/step - loss: 0.6239 - accuracy: 0.6484 - val_loss: 0.5630 - val_accuracy: 0.7167\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 23s 43ms/step - loss: 0.5430 - accuracy: 0.7299 - val_loss: 0.5365 - val_accuracy: 0.7420\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 24s 44ms/step - loss: 0.5087 - accuracy: 0.7556 - val_loss: 0.5385 - val_accuracy: 0.7353\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 58s 105ms/step - loss: 0.6375 - accuracy: 0.6347 - val_loss: 0.5876 - val_accuracy: 0.6909\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 54s 98ms/step - loss: 0.5457 - accuracy: 0.7273 - val_loss: 0.5212 - val_accuracy: 0.7447\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 53s 97ms/step - loss: 0.5031 - accuracy: 0.7559 - val_loss: 0.5039 - val_accuracy: 0.7610\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 63s 109ms/step - loss: 0.6518 - accuracy: 0.6133 - val_loss: 0.5875 - val_accuracy: 0.6835\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 55s 100ms/step - loss: 0.5488 - accuracy: 0.7232 - val_loss: 0.5232 - val_accuracy: 0.7483\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 57s 104ms/step - loss: 0.5025 - accuracy: 0.7549 - val_loss: 0.4940 - val_accuracy: 0.7644\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 54s 98ms/step - loss: 0.6171 - accuracy: 0.6622 - val_loss: 0.5777 - val_accuracy: 0.7027\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 55s 100ms/step - loss: 0.5404 - accuracy: 0.7309 - val_loss: 0.5366 - val_accuracy: 0.7288\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 52s 95ms/step - loss: 0.5030 - accuracy: 0.7556 - val_loss: 0.5340 - val_accuracy: 0.7374\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 141s 258ms/step - loss: 0.6259 - accuracy: 0.6447 - val_loss: 0.5881 - val_accuracy: 0.6943\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 131s 240ms/step - loss: 0.5373 - accuracy: 0.7269 - val_loss: 0.5636 - val_accuracy: 0.7135\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 136s 249ms/step - loss: 0.4969 - accuracy: 0.7594 - val_loss: 0.4859 - val_accuracy: 0.7699\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 148s 269ms/step - loss: 0.6390 - accuracy: 0.6286 - val_loss: 0.6161 - val_accuracy: 0.6563\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 146s 268ms/step - loss: 0.5299 - accuracy: 0.7405 - val_loss: 0.4846 - val_accuracy: 0.7720\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 149s 274ms/step - loss: 0.4660 - accuracy: 0.7810 - val_loss: 0.4513 - val_accuracy: 0.7900\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 17s 30ms/step - loss: 0.6953 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.4984\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 16s 29ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5016\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 16s 29ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.4984\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 26s 46ms/step - loss: 0.6623 - accuracy: 0.5886 - val_loss: 0.5999 - val_accuracy: 0.6801\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 24s 44ms/step - loss: 0.5694 - accuracy: 0.7059 - val_loss: 0.5406 - val_accuracy: 0.7309\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 24s 44ms/step - loss: 0.5183 - accuracy: 0.7478 - val_loss: 0.5045 - val_accuracy: 0.7602\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 26s 46ms/step - loss: 0.6556 - accuracy: 0.6019 - val_loss: 0.6075 - val_accuracy: 0.6831\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 29s 53ms/step - loss: 0.5533 - accuracy: 0.7164 - val_loss: 0.5137 - val_accuracy: 0.7465\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 25s 46ms/step - loss: 0.5011 - accuracy: 0.7568 - val_loss: 0.4985 - val_accuracy: 0.7507\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 31s 55ms/step - loss: 0.6308 - accuracy: 0.6451 - val_loss: 0.5686 - val_accuracy: 0.7056\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 29s 54ms/step - loss: 0.5428 - accuracy: 0.7296 - val_loss: 0.5339 - val_accuracy: 0.7376\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 27s 50ms/step - loss: 0.4971 - accuracy: 0.7586 - val_loss: 0.5437 - val_accuracy: 0.7282\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 53s 95ms/step - loss: 0.6086 - accuracy: 0.6642 - val_loss: 0.5458 - val_accuracy: 0.7274\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 54s 98ms/step - loss: 0.5154 - accuracy: 0.7464 - val_loss: 0.5046 - val_accuracy: 0.7556\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 55s 100ms/step - loss: 0.4723 - accuracy: 0.7734 - val_loss: 0.4634 - val_accuracy: 0.7769\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 58s 104ms/step - loss: 0.6577 - accuracy: 0.5974 - val_loss: 0.6386 - val_accuracy: 0.6438\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 55s 100ms/step - loss: 0.5561 - accuracy: 0.7158 - val_loss: 0.5315 - val_accuracy: 0.7365\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 51s 94ms/step - loss: 0.4992 - accuracy: 0.7560 - val_loss: 0.4931 - val_accuracy: 0.7607\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 69s 124ms/step - loss: 0.6163 - accuracy: 0.6581 - val_loss: 0.5688 - val_accuracy: 0.7016\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 68s 125ms/step - loss: 0.5304 - accuracy: 0.7379 - val_loss: 0.5487 - val_accuracy: 0.7194\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 68s 125ms/step - loss: 0.4707 - accuracy: 0.7772 - val_loss: 0.5235 - val_accuracy: 0.7477\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 125s 227ms/step - loss: 0.6426 - accuracy: 0.6238 - val_loss: 0.5930 - val_accuracy: 0.6940\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 123s 225ms/step - loss: 0.5494 - accuracy: 0.7228 - val_loss: 0.5017 - val_accuracy: 0.7610\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 138s 253ms/step - loss: 0.4983 - accuracy: 0.7560 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 149s 272ms/step - loss: 0.6522 - accuracy: 0.6083 - val_loss: 0.5788 - val_accuracy: 0.7010\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 151s 277ms/step - loss: 0.5416 - accuracy: 0.7312 - val_loss: 0.5125 - val_accuracy: 0.7453\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 149s 274ms/step - loss: 0.4661 - accuracy: 0.7792 - val_loss: 0.4658 - val_accuracy: 0.7773\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 18s 29ms/step - loss: 0.6252 - accuracy: 0.6402 - val_loss: 0.5985 - val_accuracy: 0.6782\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 15s 28ms/step - loss: 0.5333 - accuracy: 0.7342 - val_loss: 0.5417 - val_accuracy: 0.7304\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 15s 28ms/step - loss: 0.4826 - accuracy: 0.7701 - val_loss: 0.5255 - val_accuracy: 0.7437\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546/546 [==============================] - 24s 43ms/step - loss: 0.6264 - accuracy: 0.6386 - val_loss: 0.5653 - val_accuracy: 0.7179\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 23s 42ms/step - loss: 0.5214 - accuracy: 0.7442 - val_loss: 0.5253 - val_accuracy: 0.7418\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 23s 42ms/step - loss: 0.4765 - accuracy: 0.7735 - val_loss: 0.4886 - val_accuracy: 0.7590\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 26s 46ms/step - loss: 0.6658 - accuracy: 0.5815 - val_loss: 0.6121 - val_accuracy: 0.6752\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 25s 45ms/step - loss: 0.5624 - accuracy: 0.7097 - val_loss: 0.5594 - val_accuracy: 0.7086\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 25s 45ms/step - loss: 0.4930 - accuracy: 0.7626 - val_loss: 0.4733 - val_accuracy: 0.7745\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 37s 67ms/step - loss: 0.6091 - accuracy: 0.6677 - val_loss: 0.5500 - val_accuracy: 0.7282\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 32s 58ms/step - loss: 0.5106 - accuracy: 0.7472 - val_loss: 0.5503 - val_accuracy: 0.7183\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 30s 55ms/step - loss: 0.4396 - accuracy: 0.7925 - val_loss: 0.5331 - val_accuracy: 0.7390\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 51s 91ms/step - loss: 0.6046 - accuracy: 0.6611 - val_loss: 0.6075 - val_accuracy: 0.6682\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 49s 90ms/step - loss: 0.5105 - accuracy: 0.7488 - val_loss: 0.6011 - val_accuracy: 0.6812\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 49s 90ms/step - loss: 0.4633 - accuracy: 0.7826 - val_loss: 0.4610 - val_accuracy: 0.7783\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 54s 97ms/step - loss: 0.6717 - accuracy: 0.5713 - val_loss: 0.6306 - val_accuracy: 0.6510\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 52s 95ms/step - loss: 0.5989 - accuracy: 0.6786 - val_loss: 0.5581 - val_accuracy: 0.7107\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 52s 95ms/step - loss: 0.5271 - accuracy: 0.7394 - val_loss: 0.5265 - val_accuracy: 0.7388\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 90s 164ms/step - loss: 0.6264 - accuracy: 0.6454 - val_loss: 0.6112 - val_accuracy: 0.6746\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 88s 161ms/step - loss: 0.5160 - accuracy: 0.7453 - val_loss: 0.5421 - val_accuracy: 0.7241\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 86s 158ms/step - loss: 0.4468 - accuracy: 0.7869 - val_loss: 0.5451 - val_accuracy: 0.7423\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 1855s 3s/step - loss: 0.6491 - accuracy: 0.6189 - val_loss: 0.6088 - val_accuracy: 0.6610\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 124s 228ms/step - loss: 0.5424 - accuracy: 0.7260 - val_loss: 0.5689 - val_accuracy: 0.7043\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 126s 230ms/step - loss: 0.4722 - accuracy: 0.7730 - val_loss: 0.4925 - val_accuracy: 0.7639\n",
      "Epoch 1/3\n",
      "546/546 [==============================] - 135s 246ms/step - loss: 0.6755 - accuracy: 0.5655 - val_loss: 0.6239 - val_accuracy: 0.6513\n",
      "Epoch 2/3\n",
      "546/546 [==============================] - 745s 1s/step - loss: 0.5848 - accuracy: 0.6926 - val_loss: 0.5245 - val_accuracy: 0.7328\n",
      "Epoch 3/3\n",
      "546/546 [==============================] - 131s 239ms/step - loss: 0.4843 - accuracy: 0.7659 - val_loss: 0.4519 - val_accuracy: 0.7851\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X/255.0)\n",
    "Y = np.array(Y)\n",
    "\n",
    "import time \n",
    "\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-node-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            \n",
    "            for l in range(conv_layer - 1):\n",
    "                model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "            \n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            model.fit(X, Y,\n",
    "                      batch_size=32,\n",
    "                      epochs=3,\n",
    "                      validation_split=0.3,\n",
    "                      callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
